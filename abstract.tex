\section*{Abstract}
Learning representations of the data that make it easier to extract useful information when building classifiers or other predictors is referred to as representation learning. Recent years have brought a tremendous advancement in this area of Artificial Intelligence. It seems, however, as if this development neglected the benefits Bayesian approach could provide, namely uncertainty quantification, interpretability, or better latent space properties resulting in more universal and quality representations. This work tries to bridge this gap by introducing, analyzing, and testing a cross-section of Bayesian representation learning models by an appropriate theoretical introduction, along with an observational and quantitative study.

\section*{Streszczenie}
Uczenie się reprezentacji danych, które ułatwiają wydobywanie przydatnych informacji podczas budowania klasyfikatorów lub innych predyktorów, jest nazywane uczeniem reprezentacji. Ostatnie lata przyniosły ogromny postęp w tej dziedzinie sztucznej inteligencji. Wydaje się jednak, że rozwój ten pomija korzyści, jakie może zapewnić podejście bayesowskie, a mianowicie kwantyfikację niepewności, interpretowalność lub lepsze właściwości przestrzeni ukrytej, co skutkuje bardziej uniwersalnymi i jakościowymi reprezentacjami. Niniejsza praca próbuje wypełnić tę lukę, przedstawiając, analizując i testując przekrój modeli uczenia reprezentacji bayesowskich poprzez odpowiednie wprowadzenie teoretyczne, wraz z badaniami obserwacyjnymi oraz ilościowymi.